# Alfa Hack 2024

> Кейс "Отток юридических лиц из расчетно-кассового обслуживания"

Leaderboard ROC-AUC: `0.817764`
## Проблема

Сейчас идет цифровизация масштабными темпами, из-за чего простым менеджерам и работникам приходиться сталкиваться с задачами Машинного обучения. Но большинство людей не умееют программировать, тем более обучать модели и подбирать гиперпараметры для них. Для этого есть AutoML, которому необходимо загрузить только данные для обучения. Благодаря этому процесс работы идет быстрее и эффективнее.

## Задача

Задачей финала является создание AutoML-решения, способного решать задачи бинарной классификации на различных данных, и учитывающее изменения распределений в них. Нам были даны 6 датасетов для проверки решения, 4 датасета валидационных и еще 5 датасетов для private leaderboard.

## Оценка качества

В качестве метрики оценки, на каждом из датасетов используется метрика ROC-AUC, оценивающая качество предсказания модели на выделенном наборе данных. После расчета метрики на 9 наборах данных, 4 метрики определяют положение команды в публичном лидерборде, а оставшиеся 5 - в приватном, результаты которого будут открыты после окончания соревнования.

## Место

Мы заняли 5 место, разделив с другой командой по private leaderboard. Но весь хакатон мы держались первыми на public leaderboard, но попали под шейкап.

## Вознаграждение
Общий призовой фонд конкурса  500 000 ₽
1 место: 250 000 ₽
2 место: 150 000 ₽
3 место: 100 000 ₽

## Решение:

1. [AutoGluon](notebooks/1.%20AutoGluon.ipynb) - запускать на CPU

```python
Ensemble Weights: {
  'LightGBMXT_BAG_L2': 0.48,
  'LightGBM_BAG_L2': 0.2,
  'XGBoost_BAG_L2': 0.2,
  'CatBoost_BAG_L1': 0.04,
  'CatBoost_BAG_L2': 0.04,
  'LightGBMLarge_BAG_L2': 0.04
}
```

- val: 0.8145
- lb: 0.817466

2. [LightAutoML](notebooks/2.%20LightAutoML.ipynb) - запускать на CPU

```python
Final prediction for new objects (level 0) =
   0.17114 * (7 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +
   0.65639 * (7 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +
   0.11405 * (7 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +
   0.05842 * (7 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost)
```

- val: 0.8141
- lb: 0.817412

3. [Blending](notebooks/3.%20Blending.ipynb)

```python
Result = 0.6 * LightAutoML + 0.4 * AutoGluon
```

- lb: 0.817764
## Private leaderboard
